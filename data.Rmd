# Data 

## Sources

In our search for US colleges statistics, we focused on the US colleges' admission process. The U.S. Department of Education's National Center for Education Statistics (NCES) collects such data annually. We decided to analyze Integrated Postsecondary Education Data System (IPEDS) data from the National Center for Education Statistics (NCES), which contains all the college-level information we need. It is collected by conducting several interrelated surveys from about 6,400 colleges, universities, and technical and vocational institutions that participate in the federal student aid programs, hence we decided this is reliable and adequate data for our analysis. 

The other datasets we found were subsets of this data. This was the most extensive dataset that could be used to analyze, explore and visualize, to answer our question of “How do we select the ideal college for our higher education?”

For each year, NCES releases the data twice - the first being provisional data and then the final data. The provisional data has been said to undergo all the NCES data quality control procedures. This is released after each year. The final data includes the revisions institutions make. This is released after two years.

Since the data itself is collected from surveys answered by institutions, there is an inherent unsureness/skepticism about the correctness of the data. As we saw this year, Columbia University acknowledged giving false data for the US News ranking, attributing it to outdated methodologies. For our purpose, we assume the correctness of the data reported in surveys.

We can contact [NCES](https://nces.ed.gov/help/webmail/) if we have any questions about the data that is collected. 


## Cleaning / transformation


```{r}
library(dplyr)
library(tibble)
library(tidyr)
library(ggplot2)
library(forcats)
library(RODBC)
library(reshape2)
library(MASS)
library(plotly)
library(gtable)
library(usmap)
library(ggplot2)
library(choroplethr)
library(choroplethrMaps)
library(redav)
```

We are using the tables ADM2019, HD2019, IC2019_AY, SFA1819_P1, DRVGR2019, EF2019A, and EF2019D from the access database to perform EDA and visualize trends in the data.

ADM2019: This table contains information about the undergraduate selection process for entering first-time, degree/certificate-seeking students. This includes information about admission considerations,  applicants, applicants that were admitted, and admitted students who enrolled. SAT and ACT test scores are included for institutions, that require test scores for admission. These data are applicable for institutions that do not have an open admissions policy for entering first-time students. Writing scores for both SAT and ACT are no longer collected.

HD2019: This table contains directory information for every institution in the 2019 IPEDS universe.  Includes name, address, city, state, zip code and various other information. We used it to match state and institute name with UNITID (which is used in all other tables).

IC2019_AY: This table contains data on student charges for a full academic year. The price of attendance of full-time first-time undergraduates that are made available to the public on College Navigator are included in this table.  Price of attendance includes amounts for published tuition and required fees, books and supplies, room and board and other expenses.

SFA1819_P1: This table contains data on the number of full-time, first-time degree/certificate-seeking undergraduate students and all undergraduate students who receive different types of student financial aid, including grants and loans, from different sources at each institution.

DRVGR2019: Table contains the graduation rates derived from the graduation rate data for selected cohorts. Graduation rates grouped by gender are also provided.

EF2019A: This table contains the number of students enrolled in the fall, by race/ethnicity, gender, attendance (full- or part-time) status and level of student. Each record will contain the total enrollment,  enrollment for men and women, and the total enrollment and enrollment for men and women for all nine race/ethnicity categories. 

EF2019D: This table contains data on the total entering class, first-year retention rates and the student-to-faculty ratio. Student-to-faculty ratio is defined as  total FTE students not in graduate or professional programs divided by total FTE instructional staff not teaching in graduate or professional programs. All data in this table are applicable only to institutions with undergraduate students.

Retrieving data from Microsoft Access Database:
We need to install the 64-bit database engine from: [microsoft](https://www.microsoft.com/en-US/download/details.aspx?id=13255).
This download will install a set of components that can be used to facilitate transfer of data between 2010 Microsoft Office System files and non-Microsoft Office applications.
We use the odbcDriverConnect function from the RODBC library to transform the data from access database format into a usable dataframe in R. We didn't require any data cleaning or transformation before EDA.

**For any clarification on the variable names or levels of categorical variables and what they represent, please see documentation in 'IPEDS201920TableDocs.xlsx', in 'IPEDS_2019-20_Final' folder**

```{r}
DRIVERINFO <- "Driver={Microsoft Access Driver (*.mdb, *.accdb)};"
MDBPATH <- "C:\\Users\\kanak\\Desktop\\EDAV Final Project\\Data\\IPEDS201920.accdb"
PATH <- paste0(DRIVERINFO, "DBQ=", MDBPATH)

channel <- odbcDriverConnect(PATH)

adm2019 <- sqlQuery(channel,
               "SELECT * FROM [ADM2019];",
               stringsAsFactors = FALSE)

hd2019 <- sqlQuery(channel,
               "SELECT * FROM [HD2019];",
               stringsAsFactors = FALSE)

ic2019_ay <- sqlQuery(channel,
               "SELECT * FROM [IC2019_AY];",
               stringsAsFactors = FALSE)

sfa1819_p1 <- sqlQuery(channel,
               "SELECT * FROM [SFA1819_P1];",
               stringsAsFactors = FALSE)

drvgr2019 <- sqlQuery(channel,
               "SELECT * FROM [DRVGR2019];",
               stringsAsFactors = FALSE)

ef2019d <- sqlQuery(channel,
               "SELECT * FROM [EF2019D];",
               stringsAsFactors = FALSE)

ef2019a <- sqlQuery(channel,
               "SELECT * FROM [EF2019A];",
               stringsAsFactors = FALSE)




ic2019_ay <- ic2019_ay[c('UNITID', 'CHG3AY3', 'CHG2AY3')]

sfa1819_p1 <- sfa1819_p1[c('UNITID', 'IGRNT_N', 'IGRNT_P', 'IGRNT_A')]

drvgr2019 <- drvgr2019[c('UNITID', 'GBA4RTT', 'GRRTM','GRRTW')]

hd2019 <- hd2019[c('UNITID', 'INSTNM', 'STABBR')]

ef2019d <- ef2019d[c('UNITID', 'STUFACR')]

```


## Missing value analysis
```{r}
print("Missing values in ADM2019")
colSums(is.na(adm2019)) %>%
  sort(decreasing = TRUE)

print("Missing values in IC2019_AY")
colSums(is.na(ic2019_ay)) %>%
  sort(decreasing = TRUE)

print("Missing values in SFA1819_P1")
colSums(is.na(sfa1819_p1)) %>%
  sort(decreasing = TRUE)

print("Missing values in DRVGR2019")
colSums(is.na(drvgr2019)) %>%
  sort(decreasing = TRUE)

print("Missing values in HD2019")
colSums(is.na(hd2019)) %>%
  sort(decreasing = TRUE)

print("Total missing values in EF2019A")
sum(is.na(ef2019a))
print("Total missing values in EF2019D")
sum(is.na(ef2019d))

```

Checking for duplicate rows

```{r}
print("Duplicates in ADM2019")
sum(duplicated(adm2019$UNITID))
print("Duplicates in IC2019_AY")
sum(duplicated(ic2019_ay$UNITID))
print("Duplicates in SFA1819_P1")
sum(duplicated(sfa1819_p1$UNITID))
print("Duplicates in DRVGR2019")
sum(duplicated(drvgr2019$UNITID))
print("Duplicates in HD2019")
sum(duplicated(hd2019$UNITID))
print("Duplicates in EF2019D")
sum(duplicated(ef2019d$UNITID))

```
### Tables: IC2019_AY, SFA1819_P1, DRVGR2019, HD2019
Firstly, we deal with missing values in IC2019_AY, SFA1819_P1, DRVGR2019. For this step, we use plot_missing function from redav library.

```{r}
plot_missing(ic2019_ay)
plot_missing(sfa1819_p1)
plot_missing(drvgr2019)
```

We remove all the rows with missing values in IC2019_AY, SFA1819_P1. But, in the case of DRVGR2019, there are a lot of rows with missing values only from column GBA4RTT(Graduation rate - Bachelor degree within 4 years, total). Hence, we will create two dataframes. One which removes missing values from men and women graduation rates to analyze. Next, we remove the missing values in total graduation rate to analyze the total statistics. 
Next, we save the cleaned datasets in the Data folder to use for further analysis.

```{r}

ic2019_ay <- ic2019_ay %>% drop_na(colnames(ic2019_ay))
sfa1819_p1 <- sfa1819_p1 %>% drop_na(colnames(sfa1819_p1))
drvgr2019_A <- drvgr2019 %>% drop_na(c('UNITID', 'GRRTW', 'GRRTM'))
drvgr2019_B <- drvgr2019 %>% drop_na('GBA4RTT')
hd2019 <- hd2019 %>% drop_na(colnames(hd2019))
print('Number of rows, columns in IC2019_AY')
dim(ic2019_ay)
print('Number of rows, columns in SFA1819_P1')
dim(sfa1819_p1)
print('Number of rows, columns in DRVGR2019_A')
dim(drvgr2019_A)


write.csv(ic2019_ay, "./Data/ic2019_ay.csv", row.names = FALSE)
write.csv(sfa1819_p1, "./Data/sfa1819_p1.csv", row.names = FALSE)
write.csv(drvgr2019_A, "./Data/drvgr2019_A.csv", row.names = FALSE)
write.csv(drvgr2019_B, "./Data/drvgr2019_B.csv", row.names = FALSE)
write.csv(hd2019, "./Data/hd2019.csv", row.names = FALSE)

```

In total, there are 8 continuous variables in the 3 tables (IC2019_AY, SFA1819_P1, DRVGR2019_A) combined, and a UNITID column which is the ID for each college.
HD2019 has no missing values and has 2 categorical variables and UNITID columns.


### Table: ADM2019
Now, we deal with the missing values in ADM2019 table. First we use the plot_missing function from redav library to visualize missing patterns.
(The function outputs a graph with overlapping axes and we were not able to read the x-labels. So we copy-pasted the code and rotated the x axis labels by 90 degrees, and changes the size of labels accordingly for our data)

```{r}
x = adm2019
percent = TRUE
na_count_all <- data.frame(is.na(x)) %>%	
  dplyr::group_by_all() %>%	
  dplyr::count(name = "count", sort = TRUE) %>%	
  dplyr::ungroup() %>%	
  tibble::rownames_to_column("pattern")	

na_count_all <- na_count_all %>% 
  dplyr::mutate(pattern = factor(.data$pattern, levels = nrow(na_count_all):1))

# count the number of columns with missing values; will be used later to determine if there's a "none missing" pattern	
na_count_all <- na_count_all %>% 	
  dplyr::rowwise() %>%	
  dplyr::mutate(num_missing_cols = sum(dplyr::c_across(where(is.logical))))	

# data frame for missing patterns bar chart	
na_count_by_pattern <- na_count_all[,c("pattern", "count", "num_missing_cols")]
na_count_by_pattern$none_missing <- ifelse(na_count_by_pattern$num_missing_cols == 0, TRUE, FALSE)

# data frame for missing by column bar chart	
na_count_by_column <- data.frame(is.na(x)) %>%	
  colSums() %>% 	
  sort(decreasing = TRUE) %>% 	
  tibble::enframe(name = "var", value = "count")	

# tidy and sort na_count_all by column counts	
na_count_all_tidy <- na_count_all %>% 	
  tidyr::pivot_longer(where(is.logical), names_to = "variable") %>%	
  dplyr::mutate(variable = factor(.data$variable, levels = na_count_by_column$var))  %>% 	
  dplyr::mutate(none_missing = ifelse(.data$num_missing_cols == 0, TRUE, FALSE))	

# main plot
main_plot <- ggplot2::ggplot(na_count_all_tidy, ggplot2::aes(.data$variable, .data$pattern, fill = factor(.data$value), alpha = .data$none_missing)) +	
  ggplot2::geom_tile(color = "white") +	
  ggplot2::scale_fill_manual(values = c("grey70", "mediumpurple")) +	
  ggplot2::scale_alpha_manual(values = c(.7, 1)) +	
  ggplot2::ylab("missing pattern") +	
  ggplot2::guides(fill = "none", alpha = "none") +	
  ggplot2::theme_classic(12)	+
  ggplot2::theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size=5), axis.text.y = element_text(size = 4), axis.title = element_text(size=5))

# check for "none missing" pattern
none_missing_pattern <- na_count_by_pattern %>%
  dplyr::filter(.data$none_missing) %>% dplyr::pull(.data$pattern)

if (length(none_missing_pattern) > 0) {	
  main_plot <- main_plot +	
    ggplot2::annotate("text", x = (ncol(na_count_all)-2)/2,	
             y = nrow(na_count_all) + 1 - as.numeric(as.character(none_missing_pattern)),	
             label = "complete cases", size=1.7)	
}	

# margin plots

denom <- ifelse(percent, nrow(x)/100, 1)

missing_by_column_plot <- ggplot2::ggplot(na_count_by_column, ggplot2::aes(forcats::fct_inorder(.data$var), .data$count/denom)) +	
  ggplot2::geom_col(fill = "cornflowerblue", alpha = .7) +
  ggplot2::scale_y_continuous(expand = c(0, 0), n.breaks = 3) +	
  ggplot2::xlab("") +
  ggplot2::ylab(ifelse(percent, "% rows \n missing:", "num rows \n missing:")) +	
  ggplot2::theme_linedraw(12) + 	
  ggplot2::theme(panel.grid.major.x = ggplot2::element_blank(),	
        panel.grid.minor.x = ggplot2::element_blank(),axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), text = element_text(size=4), axis.title = element_text(size=5))	

missing_by_pattern_plot <- 
  ggplot2::ggplot(na_count_by_pattern, ggplot2::aes(.data$pattern, .data$count/denom, alpha = .data$none_missing)) +
  ggplot2::geom_col(fill = "cornflowerblue") +
  ggplot2::coord_flip() +
  ggplot2::scale_y_continuous(expand = c(0, 0), n.breaks = 3) +
  ggplot2::scale_alpha_manual(values = c(.7, 1)) +
  ggplot2::xlab("") +
  ggplot2::ylab(ifelse(percent, "% rows", "row count")) +
  ggplot2::guides(alpha = "none") +
  ggplot2::theme_linedraw(12) +
  ggplot2::theme(panel.grid.major.y = ggplot2::element_blank(), 
        panel.grid.minor.y = ggplot2::element_blank(),axis.text.y = element_text(size = 4),axis.text.x = element_text(size = 5), axis.title = element_text(size=5))

if (percent) {	
  missing_by_column_plot <- missing_by_column_plot +
    ggplot2::scale_y_continuous(expand = c(0, 0), n.breaks = 5,
                       limits = c(0, 100))	
  missing_by_pattern_plot <- missing_by_pattern_plot +
    ggplot2::scale_y_continuous(expand = c(0, 0), n.breaks = 5,
                       limits = c(0, 100))	
}	

missing_by_column_plot + patchwork::plot_spacer() + 	
  main_plot + missing_by_pattern_plot + 	
  patchwork::plot_layout(widths = c(4, 1), heights = c(1, 4))
```

ENRLT is the total number of enrolled students, and ENRLM is the total number of enrolled men; the rows starting with SAT and ACT give the 25th percentile and 75th percentile scores in tests, and these are a main part of our analysis. Without these values, we cannot form meaningful hypotheses, so we are removing the schools that didn't provide these data. After this, our missing values look like this:

```{r}
adm2019 <- adm2019 %>% drop_na(c(ENRLT,ENRLM,SATVR25,SATVR75,SATMT25,SATMT75,ACTCM25,ACTCM75,ACTEN25,ACTEN75,ACTMT25,ACTMT75))

colSums(is.na(adm2019)) %>%
  sort(decreasing = TRUE)
```

The majority missing values are in Part time student enrollment statistics. These are not very pertinent to our analysis, so we are dropping these columns. Enrollment of men and total enrollment determine the women enrollment (based on responses from majority colleges), so dropping this column too, and calculating it using (Total enrollment - men enrollment) instead. After this, only missing values are 3 rows in full-time enrollment of men. These 3 rows are dropped to get a cleaned dataframe. This dataset is now saved in the Data folder for further analysis.


```{r}
adm2019 <- select(adm2019, -ENRLPTM)
adm2019 <- select(adm2019, -ENRLPTW)
adm2019 <- select(adm2019, -ENRLPT)
adm2019$ENRLW = adm2019$ENRLT - adm2019$ENRLM
adm2019$ADMSSNW = adm2019$ADMSSN - adm2019$ADMSSNM
adm2019 <- adm2019 %>% drop_na(ENRLFTM)
adm2019$ENRLFTW = adm2019$ENRLFT - adm2019$ENRLFTM
print('Number of rows, columns in ADM2019')
dim(adm2019)

write.csv(adm2019, "./Data/adm2019.csv", row.names = FALSE)
```
In this table, there are 9 categorical variables, and 26 continuous variables and a UNITID column which is the ID for each college.


### Table: EF2019A, EF2019D
As seen earlier, there is no missing value in EF2019A table, the dataset is directly saved in the Data folder.
As seen earlier, there is one missing value in EF2019D table, we dropped it to clean the dataset and saved it in the Data folder.


```{r}
write.csv(ef2019a, "./Data/ef2019a.csv", row.names = FALSE)
ef2019d <- ef2019d %>% drop_na(STUFACR)
write.csv(ef2019d, "./Data/ef2019d.csv", row.names = FALSE)

print('Number of rows, columns in EF2019A')
dim(ef2019a)
print('Number of rows, columns in EF2019D')
dim(ef2019d)
```

There are 4 categorical variables and 30 continuous variables in the EF2019A table, and 1 continuous variable in the EF2019D table, along with the UNITID column.

In total, our datasets have 15 categorical variables and 65 continuous variables (some of these are dependent on other variables) and a common UNITID column for each college.

Note:
There are other tables that have processed admission statistics like percent yields in admission for each gender, etc, but we are using the raw data tables collected from the surveys only, and analysing this data.



